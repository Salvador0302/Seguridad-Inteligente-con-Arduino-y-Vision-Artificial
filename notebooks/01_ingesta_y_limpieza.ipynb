{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee50a022",
   "metadata": {},
   "source": [
    "# 01 - Ingesta y Limpieza de Datos\n",
    "\n",
    "**Proyecto:** Seguridad Inteligente con Arduino y Visión Artificial\n",
    "\n",
    "Este notebook realiza la ingesta de datos desde la exportación de Telegram y ejecuta el proceso de limpieza inicial.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06618186",
   "metadata": {},
   "source": [
    "## 1. Configuración Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e28db04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Importaciones estándar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Importar módulo personalizado (ahora definido en la siguiente celda)\n",
    "# from ingest import TelegramDataIngestor\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Opciones de pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"✓ Librerías importadas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64c924e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clase TelegramDataIngestor (sustituye al módulo src/ingest.py)\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "class TelegramDataIngestor:\n",
    "    \"\"\"Clase para ingerir y procesar datos de exportación de Telegram.\"\"\"\n",
    "    \n",
    "    def __init__(self, config_path: str = \"configs/config.yaml\"):\n",
    "        \"\"\"\n",
    "        Inicializa el ingestor de datos.\n",
    "        \n",
    "        Args:\n",
    "            config_path: Ruta al archivo de configuración YAML\n",
    "        \"\"\"\n",
    "        with open(config_path, 'r') as f:\n",
    "            self.config = yaml.safe_load(f)\n",
    "        \n",
    "        self.raw_path = Path(self.config['data']['raw_path'])\n",
    "        self.processed_path = Path(self.config['data']['processed_path'])\n",
    "        self.result_file = self.config['telegram']['result_file']\n",
    "        \n",
    "    def load_telegram_export(self) -> Dict:\n",
    "        \"\"\"Carga el archivo result.json de la exportación de Telegram.\"\"\"\n",
    "        file_path = self.raw_path / self.result_file\n",
    "        if not file_path.exists():\n",
    "            raise FileNotFoundError(f\"No se encontró el archivo: {file_path}\")\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        print(f\"✓ Archivo cargado: {file_path}\")\n",
    "        print(f\"  Total de mensajes: {len(data.get('messages', []))}\")\n",
    "        return data\n",
    "\n",
    "    def _extract_text(self, text) -> str:\n",
    "        \"\"\"Extrae el texto de diferentes formatos de mensaje.\"\"\"\n",
    "        if isinstance(text, str):\n",
    "            return text\n",
    "        elif isinstance(text, list):\n",
    "            return ' '.join([t if isinstance(t, str) else t.get('text', '') for t in text])\n",
    "        return ''\n",
    "\n",
    "    def extract_messages(self, data: Dict) -> pd.DataFrame:\n",
    "        \"\"\"Extrae y procesa los mensajes del export de Telegram.\"\"\"\n",
    "        messages = data.get('messages', [])\n",
    "        records = []\n",
    "        for msg in messages:\n",
    "            record = {\n",
    "                'id': msg.get('id'),\n",
    "                'type': msg.get('type'),\n",
    "                'date': msg.get('date'),\n",
    "                'from': msg.get('from'),\n",
    "                'from_id': msg.get('from_id'),\n",
    "                'text': self._extract_text(msg.get('text', '')),\n",
    "                'photo': msg.get('photo'),\n",
    "                'has_photo': bool(msg.get('photo')),\n",
    "                'media_type': msg.get('media_type'),\n",
    "            }\n",
    "            records.append(record)\n",
    "        df = pd.DataFrame(records)\n",
    "        print(f\"✓ Extraídos {len(df)} registros\")\n",
    "        return df\n",
    "\n",
    "    def clean_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Limpia y procesa el DataFrame de mensajes.\"\"\"\n",
    "        df = df.copy()\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df['year'] = df['date'].dt.year\n",
    "        df['month'] = df['date'].dt.month\n",
    "        df['day'] = df['date'].dt.day\n",
    "        df['hour'] = df['date'].dt.hour\n",
    "        df['day_of_week'] = df['date'].dt.dayofweek\n",
    "        df['day_name'] = df['date'].dt.day_name()\n",
    "        df = df.drop_duplicates(subset=['id'])\n",
    "        df = df.sort_values('date').reset_index(drop=True)\n",
    "        print(f\"✓ Datos limpios: {len(df)} registros únicos\")\n",
    "        print(f\"  Rango de fechas: {df['date'].min()} a {df['date'].max()}\")\n",
    "        return df\n",
    "\n",
    "    def save_processed_data(self, df: pd.DataFrame, filename: Optional[str] = None):\n",
    "        \"\"\"Guarda los datos procesados en formato CSV.\"\"\"\n",
    "        if filename is None:\n",
    "            filename = self.config['data']['output_file']\n",
    "        output_path = self.processed_path / filename\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "        print(f\"✓ Datos guardados en: {output_path}\")\n",
    "\n",
    "    def run(self):\n",
    "        print(\"=== Iniciando ingesta de datos ===\\n\")\n",
    "        data = self.load_telegram_export()\n",
    "        df = self.extract_messages(data)\n",
    "        df_clean = self.clean_data(df)\n",
    "        self.save_processed_data(df_clean)\n",
    "        print(\"\\n=== Ingesta completada ===\")\n",
    "        return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449265a1",
   "metadata": {},
   "source": [
    "## 2. Ingesta de Datos\n",
    "\n",
    "Cargaremos los datos desde el archivo `result.json` exportado de Telegram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d0259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el ingestor\n",
    "ingestor = TelegramDataIngestor(config_path='../configs/config.yaml')\n",
    "\n",
    "print(\"✓ Ingestor inicializado\")\n",
    "print(f\"  Ruta de datos raw: {ingestor.raw_path}\")\n",
    "print(f\"  Ruta de datos procesados: {ingestor.processed_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9721588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar archivo de exportación de Telegram\n",
    "try:\n",
    "    data = ingestor.load_telegram_export()\n",
    "    print(\"\\n✓ Datos cargados exitosamente\")\n",
    "    print(f\"  Claves disponibles: {list(data.keys())}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"⚠ Error: {e}\")\n",
    "    print(\"\\nPor favor, coloca el archivo 'result.json' en: data/raw/telegram_export/\")\n",
    "    data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bf109b",
   "metadata": {},
   "source": [
    "## 3. Extracción y Procesamiento de Mensajes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3656ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer mensajes del archivo JSON\n",
    "if data is not None:\n",
    "    df_raw = ingestor.extract_messages(data)\n",
    "    \n",
    "    print(\"\\n=== Vista previa de los datos crudos ===\")\n",
    "    display(df_raw.head())\n",
    "    \n",
    "    print(\"\\n=== Información del DataFrame ===\")\n",
    "    print(df_raw.info())\n",
    "else:\n",
    "    print(\"⚠ No se pueden extraer mensajes sin datos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fb1ab3",
   "metadata": {},
   "source": [
    "## 4. Limpieza de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b396ca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiar y procesar los datos\n",
    "if data is not None:\n",
    "    df_clean = ingestor.clean_data(df_raw)\n",
    "    \n",
    "    print(\"\\n=== Datos limpios ===\")\n",
    "    display(df_clean.head())\n",
    "    \n",
    "    print(\"\\n=== Estadísticas básicas ===\")\n",
    "    print(f\"Total de registros: {len(df_clean)}\")\n",
    "    print(f\"Rango de fechas: {df_clean['date'].min()} a {df_clean['date'].max()}\")\n",
    "    print(f\"Columnas: {list(df_clean.columns)}\")\n",
    "else:\n",
    "    print(\"⚠ No se pueden limpiar datos sin información previa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ced5a2",
   "metadata": {},
   "source": [
    "## 5. Exploración Rápida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919bade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores nulos\n",
    "if 'df_clean' in locals():\n",
    "    print(\"=== Valores nulos por columna ===\")\n",
    "    null_counts = df_clean.isnull().sum()\n",
    "    print(null_counts[null_counts > 0])\n",
    "    \n",
    "    if null_counts.sum() == 0:\n",
    "        print(\"✓ No hay valores nulos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4726c01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución de tipos de mensajes\n",
    "if 'df_clean' in locals() and 'type' in df_clean.columns:\n",
    "    print(\"=== Distribución de tipos de mensajes ===\")\n",
    "    print(df_clean['type'].value_counts())\n",
    "    \n",
    "    # Visualización\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    df_clean['type'].value_counts().plot(kind='bar', color='steelblue')\n",
    "    plt.title('Distribución de Tipos de Mensajes')\n",
    "    plt.xlabel('Tipo')\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16fa1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eventos con fotos\n",
    "if 'df_clean' in locals() and 'has_photo' in df_clean.columns:\n",
    "    print(\"=== Eventos con fotografías ===\")\n",
    "    photo_counts = df_clean['has_photo'].value_counts()\n",
    "    print(photo_counts)\n",
    "    print(f\"\\nPorcentaje con fotos: {(photo_counts.get(True, 0) / len(df_clean) * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18485459",
   "metadata": {},
   "source": [
    "## 6. Guardar Datos Procesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a0b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame limpio\n",
    "if 'df_clean' in locals():\n",
    "    ingestor.save_processed_data(df_clean)\n",
    "    print(\"\\n✓ Datos guardados exitosamente\")\n",
    "    print(f\"  Archivo: {ingestor.processed_path / ingestor.config['data']['output_file']}\")\n",
    "else:\n",
    "    print(\"⚠ No hay datos para guardar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b4e581",
   "metadata": {},
   "source": [
    "## 7. Resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e003d722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen final\n",
    "if 'df_clean' in locals():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"RESUMEN DE INGESTA Y LIMPIEZA\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"✓ Registros totales: {len(df_clean)}\")\n",
    "    print(f\"✓ Columnas: {len(df_clean.columns)}\")\n",
    "    print(f\"✓ Rango temporal: {(df_clean['date'].max() - df_clean['date'].min()).days} días\")\n",
    "    print(f\"✓ Datos guardados en: data/processed/events_clean.csv\")\n",
    "    print(\"\\n✓ Proceso completado exitosamente\")\n",
    "    print(\"\\nPróximo paso: Ejecutar notebook 02_eda_y_features.ipynb\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"⚠ El proceso no se completó. Verifica que los datos estén disponibles.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
